# üöÄ Guia de Deploy - Gemini ChatBot

Este guia detalha como fazer o deploy gratuito do Gemini ChatBot usando **Render** para o backend e **Vercel** para o frontend.

## üìã Pr√©-requisitos

### Contas Necess√°rias
- ‚úÖ [GitHub](https://github.com) - Reposit√≥rio do projeto
- ‚úÖ [Google Cloud](https://console.cloud.google.com) - API Gemini
- ‚úÖ [Render](https://render.com) - Backend (gratuito)
- ‚úÖ [Vercel](https://vercel.com) - Frontend (gratuito)

### Chaves e Tokens
- `GEMINI_API_KEY` - Chave da API Google Gemini
- `RENDER_TOKEN` - Token do Render (opcional, para deploy autom√°tico)
- `VERCEL_TOKEN` - Token do Vercel (opcional, para deploy autom√°tico)

## üîß FASE 1: Deploy do Backend no Render

### 1.1 Preparar o Reposit√≥rio
O projeto j√° est√° configurado com:
- ‚úÖ `render.yaml` - Configura√ß√£o do Render
- ‚úÖ `backend/requirements.txt` - Depend√™ncias Python
- ‚úÖ Endpoint `/health` - Health check para o Render
- ‚úÖ Configura√ß√£o de CORS para produ√ß√£o

### 1.2 Configurar no Render

1. **Acesse o Render Dashboard**
   - V√° para [dashboard.render.com](https://dashboard.render.com)
   - Fa√ßa login com sua conta GitHub

2. **Criar Novo Web Service**
   - Clique em "New +" ‚Üí "Web Service"
   - Conecte seu reposit√≥rio GitHub
   - Selecione o reposit√≥rio `Gemini-ChatBot`

3. **Configurar o Servi√ßo**
   ```
   Name: gemini-chatbot-backend
   Environment: Python
   Build Command: pip install -r backend/requirements.txt
   Start Command: cd backend && python main.py
   Plan: Free
   ```

4. **Configurar Vari√°veis de Ambiente**
   - V√° em "Environment" ‚Üí "Environment Variables"
   - Adicione:
     ```
     GEMINI_API_KEY = sua_chave_api_aqui
     FLASK_ENV = production
     PYTHON_VERSION = 3.11.0
     ```

5. **Configurar Health Check**
   - Health Check Path: `/health`
   - Auto-Deploy: ‚úÖ Enabled

### 1.3 Deploy Autom√°tico
- O Render detectar√° automaticamente o `render.yaml`
- Cada push para `main` triggerar√° um novo deploy
- O servi√ßo ficar√° dispon√≠vel em: `https://gemini-chatbot-backend.onrender.com`

## üåê FASE 2: Deploy do Frontend no Vercel

### 2.1 Preparar o Reposit√≥rio
O projeto j√° est√° configurado com:
- ‚úÖ `vercel.json` - Configura√ß√£o do Vercel
- ‚úÖ `frontend/src/config/api.js` - Configura√ß√£o de API
- ‚úÖ URLs din√¢micas baseadas no ambiente

### 2.2 Configurar no Vercel

1. **Acesse o Vercel Dashboard**
   - V√° para [vercel.com/dashboard](https://vercel.com/dashboard)
   - Fa√ßa login com sua conta GitHub

2. **Importar Projeto**
   - Clique em "New Project"
   - Conecte seu reposit√≥rio GitHub
   - Selecione o reposit√≥rio `Gemini-ChatBot`

3. **Configurar o Projeto**
   ```
   Framework Preset: Other
   Root Directory: frontend
   Build Command: npm run build
   Output Directory: build
   Install Command: npm install
   ```

4. **Configurar Vari√°veis de Ambiente**
   - V√° em "Settings" ‚Üí "Environment Variables"
   - Adicione:
     ```
     REACT_APP_BACKEND_URL = https://gemini-chatbot-backend.onrender.com
     ```

5. **Configurar Dom√≠nio**
   - O Vercel fornecer√° um dom√≠nio `.vercel.app`
   - Voc√™ pode configurar um dom√≠nio customizado posteriormente

### 2.3 Deploy Autom√°tico
- Cada push para `main` triggerar√° um novo deploy
- Pull requests ter√£o previews autom√°ticos
- O site ficar√° dispon√≠vel em: `https://gemini-chatbot.vercel.app`

## üîê FASE 3: Configurar Secrets no GitHub

### 3.1 Secrets para CI/CD
V√° em `Settings` ‚Üí `Secrets and variables` ‚Üí `Actions`:

```
GEMINI_API_KEY = sua_chave_api_aqui
REACT_APP_BACKEND_URL = https://gemini-chatbot-backend.onrender.com
CODECOV_TOKEN = seu_token_codecov (se usar)
```

### 3.2 Secrets Opcionais (para deploy autom√°tico)
```
RENDER_TOKEN = seu_token_render
RENDER_SERVICE_ID = id_do_servico_render
VERCEL_TOKEN = seu_token_vercel
VERCEL_ORG_ID = id_da_org_vercel
VERCEL_PROJECT_ID = id_do_projeto_vercel
```

## üß™ FASE 4: Testar o Deploy

### 4.1 Testar Backend
```bash
# Testar health check
curl https://gemini-chatbot-backend.onrender.com/health

# Testar endpoint de roles
curl https://gemini-chatbot-backend.onrender.com/roles

# Testar chat (POST)
curl -X POST https://gemini-chatbot-backend.onrender.com/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "Ol√°", "role": "recruiter"}'
```

### 4.2 Testar Frontend
- Acesse: `https://gemini-chatbot.vercel.app`
- Teste a funcionalidade completa
- Verifique se est√° conectando com o backend

## üìä FASE 5: Monitoramento

### 5.1 Logs do Backend (Render)
- Dashboard do Render ‚Üí Seu servi√ßo ‚Üí "Logs"
- Logs em tempo real
- Hist√≥rico de deploys

### 5.2 Logs do Frontend (Vercel)
- Dashboard do Vercel ‚Üí Seu projeto ‚Üí "Functions"
- Logs de build e runtime
- Analytics de performance

### 5.3 M√©tricas do Backend
```
https://gemini-chatbot-backend.onrender.com/cache/stats
https://gemini-chatbot-backend.onrender.com/rate-limit/stats
```

## ‚ö†Ô∏è Pontos de Aten√ß√£o

### Limites da Camada Gratuita

#### Render (Backend)
- **750 horas/m√™s** - Suficiente para desenvolvimento
- **Cold start** - Primeira requisi√ß√£o pode ser lenta
- **Sleep ap√≥s inatividade** - 15 minutos sem tr√°fego
- **512MB RAM** - Limite de mem√≥ria

#### Vercel (Frontend)
- **Deploy ilimitado** - Para projetos pessoais
- **100GB bandwidth/m√™s** - Geralmente suficiente
- **Serverless functions** - 10 segundos timeout
- **Build time** - 100 minutos/m√™s

### Otimiza√ß√µes Recomendadas

1. **Backend**
   - Implementar cache Redis (se necess√°rio)
   - Otimizar queries de dados
   - Usar CDN para assets est√°ticos

2. **Frontend**
   - Otimizar bundle size
   - Implementar lazy loading
   - Usar service workers para cache

### Seguran√ßa

1. **Vari√°veis de Ambiente**
   - Nunca commitar secrets no c√≥digo
   - Usar sempre vari√°veis de ambiente
   - Rotacionar chaves periodicamente

2. **CORS**
   - Configurar origens espec√≠ficas em produ√ß√£o
   - N√£o usar `*` em produ√ß√£o

3. **Rate Limiting**
   - J√° implementado no backend
   - Monitorar uso e ajustar limites

## üîÑ Atualiza√ß√µes e Manuten√ß√£o

### Deploy Autom√°tico
- Push para `main` ‚Üí Deploy autom√°tico
- Pull requests ‚Üí Preview autom√°tico
- Rollback f√°cil via dashboard

### Monitoramento
- Logs em tempo real
- M√©tricas de performance
- Alertas de erro (configur√°veis)

### Backup
- C√≥digo versionado no GitHub
- Dados em JSON (versionados)
- Configura√ß√µes em vari√°veis de ambiente

## üÜò Troubleshooting

### Problemas Comuns

1. **Backend n√£o inicia**
   - Verificar `GEMINI_API_KEY`
   - Verificar logs no Render
   - Testar localmente

2. **Frontend n√£o conecta ao backend**
   - Verificar `REACT_APP_BACKEND_URL`
   - Verificar CORS no backend
   - Testar endpoints diretamente

3. **Cold start lento**
   - Normal no Render gratuito
   - Considerar upgrade para plano pago
   - Implementar health checks

### Comandos √öteis

```bash
# Testar backend local
cd backend
python main.py

# Testar frontend local
cd frontend
npm start

# Build de produ√ß√£o
cd frontend
npm run build

# Testes
cd backend && python -m pytest
cd frontend && npm test
```

## üìû Suporte

- **Render**: [docs.render.com](https://docs.render.com)
- **Vercel**: [vercel.com/docs](https://vercel.com/docs)
- **GitHub Actions**: [docs.github.com/en/actions](https://docs.github.com/en/actions)

---

**üéâ Parab√©ns! Seu Gemini ChatBot est√° agora deployado gratuitamente!** 